Unique prefix: P[domain,problem_3_aircraft_rand_5]-S[0.0001,128,lm-cut]-O[trpo]-M[actprop]-MO[num_layers=3,hidden_size=16]-T[7200]-01187665-24c6705
Log file: ./experiment-results/experiments.ex_wargame-experiments.actprop_3l-2019-07-26T15:04:56.583101/P[domain,problem_3_aircraft_rand_5]-S[0.0001,128,lm-cut]-O[trpo]-M[actprop]-MO[num_layers=3,hidden_size=16]-T[7200]-01187665-24c6705/logs.csv
Snapshot directory: ./experiment-results/experiments.ex_wargame-experiments.actprop_3l-2019-07-26T15:04:56.583101/P[domain,problem_3_aircraft_rand_5]-S[0.0001,128,lm-cut]-O[trpo]-M[actprop]-MO[num_layers=3,hidden_size=16]-T[7200]-01187665-24c6705/snapshots
Training supervised
No problem name given, will use all discovered problems
[problem_t::flatten] Randomizing actionsT vector ordering
Action parsing/translating/flattening summary:
  Total possible actions  : 54
  Total ignored (empty) a.: 0
  Total considered actions: 54
  Total early simplified a: 0
  Total simplified actions: 0

[weak relaxation] number of actions: 651

[COST/ REWARD WARNING]: The actions in given problem manipulates its COST/REWARD.
                        Bear in mind that an action cost is 1 + the manipulation.
                        Therefore if an action A increases the reward in 1, then
                        the cost of A will be 0 (= 1 + (-1)).

[medium relaxation] number of actions: 2451
[strong relaxation] number of actions: 2451
[weak relaxation] number of actions: 2451
[medium relaxation] number of actions: 2451
[strong relaxation] number of actions: 2451
Waiting 3.00s for rpyc connection
Loading problems problem_3_aircraft_rand_5
[problem_t::flatten] Randomizing actionsT vector ordering
Action parsing/translating/flattening summary:
  Total possible actions  : 54
  Total ignored (empty) a.: 0
  Total considered actions: 54
  Total early simplified a: 0
  Total simplified actions: 0

[weak relaxation] number of actions: 651

[COST/ REWARD WARNING]: The actions in given problem manipulates its COST/REWARD.
                        Bear in mind that an action cost is 1 + the manipulation.
                        Therefore if an action A increases the reward in 1, then
                        the cost of A will be 0 (= 1 + (-1)).

[medium relaxation] number of actions: 2451
[strong relaxation] number of actions: 2451
[weak relaxation] number of actions: 2451
[medium relaxation] number of actions: 2451
[strong relaxation] number of actions: 2451
Starting service and policy for problem_3_aircraft_rand_5
Waiting 3.00s for rpyc connection
hidden_size: 16, num_layers: 3, dropout: 0.000000, norm_response: 0
Reloading weight manager (resuming training)
Evaluating on problem_3_aircraft_rand_5
Evaluating policy
Trial results:
turn_limit: 300
trials: 30
all_goal_reached: [False, True, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, True, False, True, False, True, False, False, False, True, False, False, True, True]
all_exec_times: [1.6400790214538574, 0.01984119415283203, 1.421921968460083, 1.3901515007019043, 1.3964173793792725, 1.4148674011230469, 1.3960955142974854, 0.01767706871032715, 0.022273778915405273, 1.3914947509765625, 1.3879644870758057, 1.3855698108673096, 1.3864479064941406, 1.3850016593933105, 1.3833701610565186, 1.396871566772461, 1.3747920989990234, 0.017255067825317383, 1.383263349533081, 0.022363901138305664, 1.3810057640075684, 0.018381595611572266, 1.3910799026489258, 1.3867113590240479, 1.4065685272216797, 0.021921396255493164, 1.3859858512878418, 1.3866181373596191, 0.046692609786987305, 0.021889448165893555]
all_costs: [299, 3, 299, 299, 299, 299, 299, 3, 4, 299, 299, 299, 299, 299, 299, 299, 299, 3, 299, 4, 299, 3, 299, 299, 299, 4, 299, 299, 9, 4]
